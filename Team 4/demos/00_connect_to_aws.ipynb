{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "This notebook shows the connection to AWS and a Hello World with some of the services used\n",
    "\n",
    "1) S3\n",
    "2) Lambda (try the hello world from midterm)\n",
    "3) Cloud Watch\n",
    "\n",
    "To connect a key was made using IAM, and put into a local `.env` file, the credentials are temporary and will expire in 30 days. Care should be used when making these and different keys used for dev and prod.\n",
    "\n",
    "\n",
    "* outside POC environment consider different security practices such as SSO \n",
    "\n",
    "## TODO\n",
    "* TODO: get out metrics from runs\\, now that we can download them, pipe into useable place\n",
    "* TODO: try a lambda function hello world, show some utility\n",
    "* TODO: check that we are using the cloudwatch correctly generally (check book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.8 (v3.11.8:db85d51d3e, Feb  6 2024, 18:02:37) [Clang 13.0.0 (clang-1300.0.29.30)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "with open(\"../keys/aws_credentials.yaml\", \"r\") as f:\n",
    "    credentials = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize  -- using session authorization\n",
    "session = boto3.Session(aws_access_key_id=credentials[\"aws_access_key_id\"],\n",
    "                        aws_secret_access_key=credentials[\"aws_secret_access_key\"],\n",
    "                        region_name=credentials[\"region\"])\n",
    "\n",
    "s3 = session.client('s3')\n",
    "lamda_func = session.client(\"lambda\")\n",
    "cloudwatch = session.client('logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test S3 Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aws-athena-query-results-211125778552-us-east-1',\n",
       " 'cosmicai-data',\n",
       " 'cosmicai2',\n",
       " 'fmi-lambda-demo',\n",
       " 'group2-s3-bucket',\n",
       " 'group4-s3-bucket',\n",
       " 'sagemaker-studio-211125778552-3zpozdpwzcx',\n",
       " 'sagemaker-studio-211125778552-rrp76qgcj1n',\n",
       " 'sagemaker-us-east-1-211125778552',\n",
       " 'team-one-cosmic-data',\n",
       " 'team-one-s3-cosmic',\n",
       " 'team2cosmicai',\n",
       " 'team3cosmicai',\n",
       " 'team4-cosmicai']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = s3.list_buckets()\n",
    "\n",
    "# show current buckets\n",
    "b = [n[\"Name\"] for n in d[\"Buckets\"]]\n",
    "\n",
    "\n",
    "# buckets needed\n",
    "assert 'fmi-lambda-demo' in b, \"missing the lambda demo\" # midterm\n",
    "assert 'team4-cosmicai' in b, \"missing our team4 cosmicai S3 connection\" \n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Download S3 buckets\n",
    "\n",
    "* useful for later, consider putting in a src or util script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_s3_bucket(s3, bucket_name :str, local_dir:str = \"tmp\") -> None:\n",
    "    \"\"\"takes an S3 object, and a valid bucket name and downloads all the files on that Bucket\n",
    "    in the same structure and copies them to a local directory.\n",
    "    \n",
    "    PARAMS:\n",
    "        s3: a botocore s3 object\n",
    "        bucket_name: a valid s3 bucket in that object\n",
    "        local_directory: where the bucket will get copied to\n",
    "\n",
    "    for fine grained control use `s3.download_file` and for a list of valid buckets `s3.list_buckets`.\n",
    "    If local directory not specified will dump into tmp/ where this is script is called. Files downloaded\n",
    "    should have the same structure as the S3 bucket.  \n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the local directory exists\n",
    "    if not os.path.exists(local_dir):\n",
    "        print(f\"creating directory -- {local_dir}\")\n",
    "        os.makedirs(local_dir)\n",
    "\n",
    "    # List objects in the specified S3 bucket\n",
    "    objects = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    if 'Contents' in objects:\n",
    "        # Initialize tqdm progress bar\n",
    "        total_files = len(objects['Contents'])\n",
    "        with tqdm(total=total_files, desc=\"Downloading files\", unit=\"file\") as pbar:\n",
    "            for obj in objects['Contents']:\n",
    "\n",
    "                local_file_path = os.path.join(local_dir, obj['Key'])\n",
    "                \n",
    "                # Ensure the directory structure exists\n",
    "                if not os.path.exists(os.path.dirname(local_file_path)):\n",
    "                    os.makedirs(os.path.dirname(local_file_path))\n",
    "                \n",
    "                # Check if the object is a file (not a directory)\n",
    "                if not obj['Key'].endswith('/'):\n",
    "                    s3.download_file(bucket_name, obj['Key'], local_file_path)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                pbar.update(1)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(f\"No objects found in bucket {bucket_name}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage, run only if needed\n",
    "BUCKET_NAME = \"team4-cosmicai\"\n",
    "LOCAL_DIR = '..//data//raw//test'\n",
    "# download_s3_bucket(s3, BUCKET_NAME, LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m..//data//raw//test\u001b[0m\n",
      "├── payload.json\n",
      "├── \u001b[1;36mresults\u001b[0m\n",
      "│   ├── \u001b[1;36m0\u001b[0m\n",
      "│   │   ├── Results.json\n",
      "│   │   └── ResultsReduce.json\n",
      "│   └── \u001b[1;36m1\u001b[0m\n",
      "├── \u001b[1;36mscripts\u001b[0m\n",
      "│   └── \u001b[1;36mAnomaly Detection\u001b[0m\n",
      "│       ├── \u001b[1;36mFine_Tune_Model\u001b[0m\n",
      "│       │   └── Mixed_Inception_z_VITAE_Base_Img_Full_New_Full.pt\n",
      "│       ├── \u001b[1;36mInference\u001b[0m\n",
      "│       │   ├── __init__.py\n",
      "│       │   ├── \u001b[1;36mfmilib\u001b[0m\n",
      "│       │   │   ├── __init__.py\n",
      "│       │   │   ├── fmi_operations.py\n",
      "│       │   │   └── fmi_scaling_lambda.py\n",
      "│       │   ├── inference.py\n",
      "│       │   └── resized_inference.pt\n",
      "│       ├── NormalCell.py\n",
      "│       ├── Plot_Redshift.py\n",
      "│       ├── \u001b[1;36mPlots\u001b[0m\n",
      "│       ├── __init__.py\n",
      "│       └── \u001b[1;36mblocks\u001b[0m\n",
      "│           ├── concat_data.py\n",
      "│           ├── model_vit_inception.py\n",
      "│           ├── photoz.py\n",
      "│           └── split_data.py\n",
      "└── \u001b[1;36mscripts_ssd\u001b[0m\n",
      "    └── \u001b[1;36mAnomaly Detection\u001b[0m\n",
      "        ├── Astronomy_Overview.pptx\n",
      "        ├── \u001b[1;36mFine_Tune_Model\u001b[0m\n",
      "        │   └── Mixed_Inception_z_VITAE_Base_Img_Full_New_Full.pt\n",
      "        ├── \u001b[1;36mInference\u001b[0m\n",
      "        │   ├── Inference Step by Step Instructions.pdf\n",
      "        │   ├── __init__.py\n",
      "        │   ├── \u001b[1;36mfmilib\u001b[0m\n",
      "        │   │   ├── __init__.py\n",
      "        │   │   ├── fmi_operations.py\n",
      "        │   │   └── fmi_scaling_lambda.py\n",
      "        │   ├── inference.py\n",
      "        │   └── resized_inference.pt\n",
      "        ├── NormalCell.py\n",
      "        ├── Plot_Redshift.py\n",
      "        ├── \u001b[1;36mPlots\u001b[0m\n",
      "        │   ├── inference.png\n",
      "        │   └── inference.png_Results.json\n",
      "        ├── README.md\n",
      "        ├── __init__.py\n",
      "        ├── \u001b[1;36m__pycache__\u001b[0m\n",
      "        │   ├── NormalCell.cpython-311.pyc\n",
      "        │   └── Plot_Redshift.cpython-311.pyc\n",
      "        └── \u001b[1;36mblocks\u001b[0m\n",
      "            ├── \u001b[1;36m__pycache__\u001b[0m\n",
      "            │   ├── NormalCell.cpython-311.pyc\n",
      "            │   ├── Plot_Redshift.cpython-311.pyc\n",
      "            │   ├── model_mae_5chnnl.cpython-311.pyc\n",
      "            │   ├── model_vit_inception.cpython-311.pyc\n",
      "            │   └── photoz.cpython-311.pyc\n",
      "            ├── concat_data.py\n",
      "            ├── model_vit_inception.py\n",
      "            ├── photoz.py\n",
      "            └── split_data.py\n",
      "\n",
      "20 directories, 43 files\n"
     ]
    }
   ],
   "source": [
    "# check that it ran ok\n",
    "!tree ..//data//raw//test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Functions\n",
    "***\n",
    "\n",
    "* This is a place holder for the Lambda functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data\n",
    "***\n",
    "\n",
    "To pull log events, the stream is needed, to pull the stream the group is needed, broadly\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Log Groups] --> B[Log Streams]\n",
    "    B --> C[Log Events]\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### Log Groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_group_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/aws-glue/column-statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/aws-glue/jobs/error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/aws-glue/jobs/output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/aws-glue/sessions/error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/aws-glue/sessions/output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/aws-glue/testconnection/error/Redo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/aws-glue/testconnection/error/Redshift_connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/aws-glue/testconnection/error/team3-con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/aws-glue/testconnection/output/Redo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/aws-glue/testconnection/output/Redshift_conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/aws-glue/testconnection/output/team3-con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/aws/lambda/FecDataLoader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/aws/lambda/FecS3DataLoader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/aws/lambda/Team8FecAthenaQuery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/aws/lambda/Team8FecAthenaQueryInvoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/aws/lambda/aws-controltower-NotificationForwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/aws/lambda/cosmic-executor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/aws/lambda/cosmic-init</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/aws/lambda/data-parallel-init</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/aws/lambda/demo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/aws/lambda/fmi_executor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>/aws/lambda/fmi_init</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>/aws/lambda/helloWorld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/aws/lambda/resultSummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/aws/lambda/team3-data-crawler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      log_group_names\n",
       "0                         /aws-glue/column-statistics\n",
       "1                                /aws-glue/jobs/error\n",
       "2                               /aws-glue/jobs/output\n",
       "3                            /aws-glue/sessions/error\n",
       "4                           /aws-glue/sessions/output\n",
       "5                 /aws-glue/testconnection/error/Redo\n",
       "6   /aws-glue/testconnection/error/Redshift_connec...\n",
       "7            /aws-glue/testconnection/error/team3-con\n",
       "8                /aws-glue/testconnection/output/Redo\n",
       "9   /aws-glue/testconnection/output/Redshift_conne...\n",
       "10          /aws-glue/testconnection/output/team3-con\n",
       "11                          /aws/lambda/FecDataLoader\n",
       "12                        /aws/lambda/FecS3DataLoader\n",
       "13                    /aws/lambda/Team8FecAthenaQuery\n",
       "14             /aws/lambda/Team8FecAthenaQueryInvoker\n",
       "15  /aws/lambda/aws-controltower-NotificationForwa...\n",
       "16                        /aws/lambda/cosmic-executor\n",
       "17                            /aws/lambda/cosmic-init\n",
       "18                     /aws/lambda/data-parallel-init\n",
       "19                                   /aws/lambda/demo\n",
       "20                           /aws/lambda/fmi_executor\n",
       "21                               /aws/lambda/fmi_init\n",
       "22                             /aws/lambda/helloWorld\n",
       "23                          /aws/lambda/resultSummary\n",
       "24                     /aws/lambda/team3-data-crawler"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "l = []\n",
    "r = cloudwatch.describe_log_groups()\n",
    "\n",
    "for group in r['logGroups']:\n",
    "     l.append(group['logGroupName'])\n",
    "\n",
    "df_log_groups = pd.DataFrame(l, columns=[\"log_group_names\"])\n",
    "\n",
    "# general if needed\n",
    "df_log_groups[df_log_groups.log_group_names.str.contains(\"(?!.*sagemaker).*\")].head(25) # don't include sagemaker, many instances related to labs\n",
    "\n",
    "# may be interested in the cosmic ai logs\n",
    "# df_log_groups[df_log_groups.log_group_names.str.contains(\"cosmic\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Streams\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_GROUP = \"/aws/lambda/data-parallel-init\"\n",
    "\n",
    "l = []\n",
    "\n",
    "r = cloudwatch.describe_log_streams(logGroupName=LOG_GROUP)\n",
    "for stream in r['logStreams']:\n",
    "    l.append(stream['logStreamName'])\n",
    "\n",
    "df_log_streams_raw = pd.DataFrame(l, columns=[\"raw_streams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024/11/22/[$LATEST]272db91f41c1428e988f3084f113f535'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what a stream name should look like\n",
    "df_log_streams_raw.iloc[-10].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_pulled</th>\n",
       "      <th>stream_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024/11/07/</td>\n",
       "      <td>0fcf0e06f1174a16aca0adba257efc84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024/11/07/</td>\n",
       "      <td>1738a628c5cf4796b51d6c481da4b746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024/11/07/</td>\n",
       "      <td>27d9c7e9e6464016b8dfdd647c214fb5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024/11/07/</td>\n",
       "      <td>6a1b2157e1c6436db3bdc4e740fd2f41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024/11/20/</td>\n",
       "      <td>0d836483f503404fa3ad3d332da2f8c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024/11/20/</td>\n",
       "      <td>344f2b0cdf904d4a9dce3aba4e7158e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024/11/20/</td>\n",
       "      <td>586ddf9995cd4000a65778d5853521c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>0eaeff78011e4031a381ecc431f1b26a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>272db91f41c1428e988f3084f113f535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>3dd38b8393f848bfaff52e67b369a996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>537e518aa421415199fd61c08b676382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>91d65fb1bbdc4b16bfceefa75c1baecc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>f694b993c8e64b21a864193e0e067f44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024/11/22/</td>\n",
       "      <td>fdf2cc3435ef4ae99854712c81ad7324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024/11/23/</td>\n",
       "      <td>d434d74491e34da49ddba35d689823ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024/11/23/</td>\n",
       "      <td>e2d81545a6c340d8aafec45e4c4e086e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024/11/24/</td>\n",
       "      <td>8987c526cf4b4570b7e38790e2a97578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024/11/26/</td>\n",
       "      <td>fc0a48b959484db0a74183a0c597b1b1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_pulled                       stream_hash\n",
       "0   2024/11/07/  0fcf0e06f1174a16aca0adba257efc84\n",
       "1   2024/11/07/  1738a628c5cf4796b51d6c481da4b746\n",
       "2   2024/11/07/  27d9c7e9e6464016b8dfdd647c214fb5\n",
       "3   2024/11/07/  6a1b2157e1c6436db3bdc4e740fd2f41\n",
       "4   2024/11/20/  0d836483f503404fa3ad3d332da2f8c4\n",
       "5   2024/11/20/  344f2b0cdf904d4a9dce3aba4e7158e3\n",
       "6   2024/11/20/  586ddf9995cd4000a65778d5853521c8\n",
       "7   2024/11/22/  0eaeff78011e4031a381ecc431f1b26a\n",
       "8   2024/11/22/  272db91f41c1428e988f3084f113f535\n",
       "9   2024/11/22/  3dd38b8393f848bfaff52e67b369a996\n",
       "10  2024/11/22/  537e518aa421415199fd61c08b676382\n",
       "11  2024/11/22/  91d65fb1bbdc4b16bfceefa75c1baecc\n",
       "12  2024/11/22/  f694b993c8e64b21a864193e0e067f44\n",
       "13  2024/11/22/  fdf2cc3435ef4ae99854712c81ad7324\n",
       "14  2024/11/23/  d434d74491e34da49ddba35d689823ab\n",
       "15  2024/11/23/  e2d81545a6c340d8aafec45e4c4e086e\n",
       "16  2024/11/24/  8987c526cf4b4570b7e38790e2a97578\n",
       "17  2024/11/26/  fc0a48b959484db0a74183a0c597b1b1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make more readable \n",
    "\n",
    "df_log_streams = df_log_streams_raw[\"raw_streams\"].str.split(r\"\\[\\$LATEST\\]\", expand=True)\n",
    "df_log_streams.columns = [\"date_pulled\", \"stream_hash\"]\n",
    "\n",
    "df_log_streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Events\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 1732638297021, Message: INIT_START Runtime Version: python:3.12.v38\tRuntime Version ARN: arn:aws:lambda:us-east-1::runtime:7515e00d6763496e7a147ffa395ef5b0f0c1ffd6064130abb5ecde5a6d630e86\n",
      "\n",
      "Timestamp: 1732638297359, Message: [INFO]\t2024-11-26T16:24:57.359Z\t\tFound credentials in environment variables.\n",
      "\n",
      "Timestamp: 1732638297567, Message: START RequestId: a7f629b6-8625-4d16-96e9-f20fbf8b9f5e Version: $LATEST\n",
      "\n",
      "Timestamp: 1732638299159, Message: END RequestId: a7f629b6-8625-4d16-96e9-f20fbf8b9f5e\n",
      "\n",
      "Timestamp: 1732638299159, Message: REPORT RequestId: a7f629b6-8625-4d16-96e9-f20fbf8b9f5e\tDuration: 1591.85 ms\tBilled Duration: 1592 ms\tMemory Size: 128 MB\tMax Memory Used: 84 MB\tInit Duration: 543.20 ms\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can now get log events\n",
    "\n",
    "# try the latest (already in order oldest -> newest or desc)\n",
    "LOG_STREAM = df_log_streams_raw.iloc[-1].values[0]\n",
    "\n",
    "r = cloudwatch.get_log_events(logGroupName=LOG_GROUP, logStreamName=LOG_STREAM)\n",
    "\n",
    "for event in r['events']:\n",
    "    print(f\"Timestamp: {event['timestamp']}, Message: {event['message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': 1732638299159,\n",
       " 'message': 'REPORT RequestId: a7f629b6-8625-4d16-96e9-f20fbf8b9f5e\\tDuration: 1591.85 ms\\tBilled Duration: 1592 ms\\tMemory Size: 128 MB\\tMax Memory Used: 84 MB\\tInit Duration: 543.20 ms\\t\\n',\n",
       " 'ingestionTime': 1732638301093}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "      <th>ingestionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1732638297021</td>\n",
       "      <td>INIT_START Runtime Version: python:3.12.v38\\tR...</td>\n",
       "      <td>1732638301093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1732638297359</td>\n",
       "      <td>[INFO]\\t2024-11-26T16:24:57.359Z\\t\\tFound cred...</td>\n",
       "      <td>1732638301093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1732638297567</td>\n",
       "      <td>START RequestId: a7f629b6-8625-4d16-96e9-f20fb...</td>\n",
       "      <td>1732638301093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1732638299159</td>\n",
       "      <td>END RequestId: a7f629b6-8625-4d16-96e9-f20fbf8...</td>\n",
       "      <td>1732638301093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1732638299159</td>\n",
       "      <td>REPORT RequestId: a7f629b6-8625-4d16-96e9-f20f...</td>\n",
       "      <td>1732638301093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                                            message  \\\n",
       "0  1732638297021  INIT_START Runtime Version: python:3.12.v38\\tR...   \n",
       "1  1732638297359  [INFO]\\t2024-11-26T16:24:57.359Z\\t\\tFound cred...   \n",
       "2  1732638297567  START RequestId: a7f629b6-8625-4d16-96e9-f20fb...   \n",
       "3  1732638299159  END RequestId: a7f629b6-8625-4d16-96e9-f20fbf8...   \n",
       "4  1732638299159  REPORT RequestId: a7f629b6-8625-4d16-96e9-f20f...   \n",
       "\n",
       "   ingestionTime  \n",
       "0  1732638301093  \n",
       "1  1732638301093  \n",
       "2  1732638301093  \n",
       "3  1732638301093  \n",
       "4  1732638301093  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(r, record_path=[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: use regex to parse log streams?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJECT_venv",
   "language": "python",
   "name": "project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
