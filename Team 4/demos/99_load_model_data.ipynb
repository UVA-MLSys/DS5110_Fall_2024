{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "* This is intended to be a script that will download the training data from `cosmic-ai` to be able to run locally\n",
    "* showing it as a notebook to show off how it works\n",
    "* warning this takes a very long time to run and don't yet have functionality to check for checkpoints or what is already loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.8 (v3.11.8:db85d51d3e, Feb  6 2024, 18:02:37) [Clang 13.0.0 (clang-1300.0.29.30)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "with open(\"../keys/aws_credentials.yaml\", \"r\") as f:\n",
    "    credentials = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ..//data/raw/cosmic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize  -- using session authorization\n",
    "session = boto3.Session(aws_access_key_id=credentials[\"aws_access_key_id\"],\n",
    "                        aws_secret_access_key=credentials[\"aws_secret_access_key\"],\n",
    "                        region_name=credentials[\"region\"])\n",
    "\n",
    "s3 = session.client('s3')\n",
    "\n",
    "BUCKET_NAME = 'cosmicai-data' # where data should be\n",
    "LOCAL_SAVE = \"..//data/raw/cosmic_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should come from utils\n",
    "\n",
    "def download_s3_bucket(s3, bucket_name :str, local_dir:str = \"tmp\") -> None:\n",
    "    \"\"\"takes an S3 object, and a valid bucket name and downloads all the files on that Bucket\n",
    "    in the same structure and copies them to a local directory.\n",
    "    \n",
    "    PARAMS:\n",
    "        s3: a botocore s3 object\n",
    "        bucket_name: a valid s3 bucket in that object\n",
    "        local_directory: where the bucket will get copied to\n",
    "\n",
    "    for fine grained control use `s3.download_file` and for a list of valid buckets `s3.list_buckets`.\n",
    "    If local directory not specified will dump into tmp/ where this is script is called. Files downloaded\n",
    "    should have the same structure as the S3 bucket.  \n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the local directory exists\n",
    "    if not os.path.exists(local_dir):\n",
    "        print(f\"creating directory -- {local_dir}\")\n",
    "        os.makedirs(local_dir)\n",
    "\n",
    "    # List objects in the specified S3 bucket\n",
    "    objects = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    if 'Contents' in objects:\n",
    "        # Initialize tqdm progress bar\n",
    "        total_files = len(objects['Contents'])\n",
    "        with tqdm(total=total_files, desc=\"Downloading files\", unit=\"file\") as pbar:\n",
    "            for obj in objects['Contents']:\n",
    "\n",
    "                local_file_path = os.path.join(local_dir, obj['Key'])\n",
    "                \n",
    "                # Ensure the directory structure exists\n",
    "                if not os.path.exists(os.path.dirname(local_file_path)):\n",
    "                    os.makedirs(os.path.dirname(local_file_path))\n",
    "                \n",
    "                # Check if the object is a file (not a directory)\n",
    "                if not obj['Key'].endswith('/'):\n",
    "                    s3.download_file(bucket_name, obj['Key'], local_file_path)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                pbar.update(1)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(f\"No objects found in bucket {bucket_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading files: 100%|██████████| 1000/1000 [1:07:02<00:00,  4.02s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_s3_bucket(s3, bucket_name = BUCKET_NAME, local_dir = LOCAL_SAVE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13G\t..//data/raw/cosmic_data/100MB\n",
      "8.5G\t..//data/raw/cosmic_data/10MB\n",
      " 21G\t..//data/raw/cosmic_data\n"
     ]
    }
   ],
   "source": [
    "!du -h ..//data/raw/cosmic_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJECT_venv",
   "language": "python",
   "name": "project_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
